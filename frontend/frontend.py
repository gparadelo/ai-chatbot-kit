import streamlit as st
import httpx
import os
import time
import uuid
import json

# Page config
st.set_page_config(page_title="AI Chatbot Kit", layout="centered")

# API base URL - read from environment variable
API_BASE_URL = os.getenv("API_URL")
if not API_BASE_URL:
    st.error("API_URL environment variable is not set")
    st.stop()

# Remove trailing slash if present
API_BASE_URL = API_BASE_URL.rstrip('/')

# Construct endpoint URLs
CHAT_ENDPOINT = f"{API_BASE_URL}/api/chat/"

# Streamed response function for API calls
def get_api_response(message, thread_id):
    try:
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                CHAT_ENDPOINT,
                json={
                    "message": message,
                    "thread_id": thread_id
                }
            )
        
        if response.status_code == 200:
            result = response.json()
            bot_response = result.get("response", "Sorry, I couldn't process that.")
            # Update thread_id in case it was generated by the backend
            returned_thread_id = result.get("thread_id")
            if returned_thread_id:
                st.session_state.thread_id = returned_thread_id
        else:
            bot_response = f"Error: {response.status_code}"
            
    except Exception as e:
        bot_response = f"Connection error: {str(e)}"
    
    # Stream the response word by word
    for word in bot_response.split():
        yield word + " "
        time.sleep(0.05)

# Initialize chat history and thread_id first
if "messages" not in st.session_state:
    st.session_state.messages = []

if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())

st.title("AI Chatbot Kit")


# Add new conversation button in the header area (cleaned up)
col1, col2 = st.columns([3, 1])
with col1:
    # Removed the caption text
    pass
        
with col2:
    if st.button("New Chat", use_container_width=True):
        st.session_state.thread_id = str(uuid.uuid4())
        st.session_state.messages = []
        st.rerun()

# --- Display Existing Messages (containers without visual effect) ---
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.container():
            st.markdown(f"**{message['content']}**")
    else:
        with st.container():
            st.markdown(message["content"])

# --- User Input and Response Generation (removed spinner, kept word-by-word) ---
if prompt := st.chat_input("What would you like to know?"):
    # Append the user's prompt to the chat history
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Display the user's message
    with st.container():
        st.markdown(f"**{prompt}**")

    # Display assistant response with word-by-word streaming
    with st.container():
        # Call your existing API function to get a response
        response_stream = get_api_response(prompt, st.session_state.thread_id)
        
        # Display the streaming effect word by word
        message_placeholder = st.empty()
        full_response = ""
        
        # Stream the response word by word (matching Gemini style)
        for word in response_stream:
            full_response += word
            time.sleep(0.05)  # Simulate a slight delay for better streaming effect
            message_placeholder.markdown(f"{full_response}â–Œ")
        
        # Final message without cursor
        message_placeholder.markdown(full_response)
        
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": full_response})
